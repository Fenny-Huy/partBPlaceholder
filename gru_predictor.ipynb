{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b1e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/gru_predictor.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class GRUTrafficPredictor:\n",
    "    def __init__(self, data_pkl: str, models_dir: str):\n",
    "        \"\"\"\n",
    "        data_pkl:    path to your traffic_model_ready.csv (or .pkl)\n",
    "        models_dir:  directory where you saved gru_model.h5\n",
    "        \"\"\"\n",
    "        # 1) load & sort the volume DataFrame\n",
    "            \n",
    "        self.df = pd.read_csv(data_pkl, parse_dates=[\"Timestamp\"])\n",
    "        self.df = self.df.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "        # 2) keep the array of timestamps for indexing\n",
    "        self.timestamps = pd.to_datetime(self.df[\"Timestamp\"]).values\n",
    "\n",
    "        # 3) extract & fit a scaler on the raw volume series\n",
    "        vols = self.df[\"Volume\"].values.reshape(-1, 1)\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.vols_scaled = self.scaler.fit_transform(vols)\n",
    "\n",
    "        # 4) loads the pretrained GRU model\n",
    "        model_path = os.path.join(models_dir, \"gru_model.h5\")\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "        # 5) infer the window length from the model’s input shape\n",
    "        #    (shape is (None, window_length, 1))\n",
    "        _, self.seq_len, _ = self.model.input_shape\n",
    "\n",
    "    def predict(self, site_id: str, arm: str, timestamp: str) -> float:\n",
    "        \"\"\"\n",
    "        Called from main.py as predictor.predict(A, loc, timestamp).\n",
    "        We ignore `site_id` and `arm` here, since this GRU is univariate.\n",
    "        \"\"\"\n",
    "        # find the insertion index for the split timestamp\n",
    "        idx = np.searchsorted(self.timestamps, np.datetime64(timestamp))\n",
    "\n",
    "        # grab the preceding window\n",
    "        start = idx - self.seq_len\n",
    "        if start < 0:\n",
    "            raise ValueError(\"Not enough history before \" + timestamp)\n",
    "        window = self.vols_scaled[start:idx]\n",
    "\n",
    "        # predict next step\n",
    "        y_scaled = self.model.predict(window[np.newaxis, ...])[0, 0]\n",
    "\n",
    "        # inverse‐scale and return volumetric flow\n",
    "        return float(self.scaler.inverse_transform([[y_scaled]])[0, 0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
